- data=aime_val
- model=gemini_2_5_flash_lite_thinking
- generation=gemini_thinking_16k
- generation.ignore_cache=true
- generation.max_tokens=4096
- generation.n=3
