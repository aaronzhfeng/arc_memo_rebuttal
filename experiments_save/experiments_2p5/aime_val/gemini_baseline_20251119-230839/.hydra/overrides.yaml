- data=aime_val
- model=gemini_2_5_flash_lite_thinking
- generation=gemini_thinking_16k
- generation.ignore_cache=true
